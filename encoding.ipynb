{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import the necessary packages\n",
    "from imutils import paths\n",
    "import face_recognition\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "\"\"\"ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--dataset\", required=True,\n",
    "\thelp=\"path to input directory of faces + images\")\n",
    "ap.add_argument(\"-e\", \"--encodings\", required=True,\n",
    "\thelp=\"path to serialized db of facial encodings\")\n",
    "ap.add_argument(\"-d\", \"--detection-method\", type=str, default=\"cnn\",\n",
    "\thelp=\"face detection model to use: either `hog` or `cnn`\")\n",
    "args = vars(ap.parse_args())\n",
    "\"\"\"  \n",
    "args={'dataset':'dataset','encodings':'encodings.pickle','detection_method':'hog'}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] quantifying faces...\n"
     ]
    }
   ],
   "source": [
    "# grab the paths to the input images in our dataset, then initialize\n",
    "# out data list (which we'll soon populate)\n",
    "print(\"[INFO] quantifying faces...\")\n",
    "imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing image 1/129\n",
      "dataset\\00000000.jpg\n",
      "[INFO] processing image 2/129\n",
      "dataset\\00000001.jpg\n",
      "[INFO] processing image 3/129\n",
      "dataset\\00000002.jpg\n",
      "[INFO] processing image 4/129\n",
      "dataset\\00000003.jpg\n",
      "[INFO] processing image 5/129\n",
      "dataset\\00000004.jpg\n",
      "[INFO] processing image 6/129\n",
      "dataset\\00000005.jpg\n",
      "[INFO] processing image 7/129\n",
      "dataset\\00000006.jpg\n",
      "[INFO] processing image 8/129\n",
      "dataset\\00000007.jpg\n",
      "[INFO] processing image 9/129\n",
      "dataset\\00000008.jpg\n",
      "[INFO] processing image 10/129\n",
      "dataset\\00000009.jpg\n",
      "[INFO] processing image 11/129\n",
      "dataset\\00000010.jpg\n",
      "[INFO] processing image 12/129\n",
      "dataset\\00000011.jpg\n",
      "[INFO] processing image 13/129\n",
      "dataset\\00000012.jpg\n",
      "[INFO] processing image 14/129\n",
      "dataset\\00000013.jpg\n",
      "[INFO] processing image 15/129\n",
      "dataset\\00000014.jpg\n",
      "[INFO] processing image 16/129\n",
      "dataset\\00000015.jpg\n",
      "[INFO] processing image 17/129\n",
      "dataset\\00000016.jpg\n",
      "[INFO] processing image 18/129\n",
      "dataset\\00000017.jpg\n",
      "[INFO] processing image 19/129\n",
      "dataset\\00000018.jpg\n",
      "[INFO] processing image 20/129\n",
      "dataset\\00000019.jpg\n",
      "[INFO] processing image 21/129\n",
      "dataset\\00000020.jpg\n",
      "[INFO] processing image 22/129\n",
      "dataset\\00000021.jpg\n",
      "[INFO] processing image 23/129\n",
      "dataset\\00000022.jpg\n",
      "[INFO] processing image 24/129\n",
      "dataset\\00000023.jpg\n",
      "[INFO] processing image 25/129\n",
      "dataset\\00000024.jpg\n",
      "[INFO] processing image 26/129\n",
      "dataset\\00000025.jpg\n",
      "[INFO] processing image 27/129\n",
      "dataset\\00000026.jpg\n",
      "[INFO] processing image 28/129\n",
      "dataset\\00000027.jpg\n",
      "[INFO] processing image 29/129\n",
      "dataset\\00000028.jpg\n",
      "[INFO] processing image 30/129\n",
      "dataset\\00000029.jpg\n",
      "[INFO] processing image 31/129\n",
      "dataset\\00000030.jpg\n",
      "[INFO] processing image 32/129\n",
      "dataset\\00000031.jpg\n",
      "[INFO] processing image 33/129\n",
      "dataset\\00000032.jpg\n",
      "[INFO] processing image 34/129\n",
      "dataset\\00000033.jpg\n",
      "[INFO] processing image 35/129\n",
      "dataset\\00000034.jpg\n",
      "[INFO] processing image 36/129\n",
      "dataset\\00000035.jpg\n",
      "[INFO] processing image 37/129\n",
      "dataset\\00000036.jpg\n",
      "[INFO] processing image 38/129\n",
      "dataset\\00000037.jpg\n",
      "[INFO] processing image 39/129\n",
      "dataset\\00000038.jpg\n",
      "[INFO] processing image 40/129\n",
      "dataset\\00000039.jpg\n",
      "[INFO] processing image 41/129\n",
      "dataset\\00000040.jpg\n",
      "[INFO] processing image 42/129\n",
      "dataset\\00000041.jpg\n",
      "[INFO] processing image 43/129\n",
      "dataset\\00000042.jpg\n",
      "[INFO] processing image 44/129\n",
      "dataset\\00000043.jpg\n",
      "[INFO] processing image 45/129\n",
      "dataset\\00000044.jpg\n",
      "[INFO] processing image 46/129\n",
      "dataset\\00000045.jpg\n",
      "[INFO] processing image 47/129\n",
      "dataset\\00000046.jpg\n",
      "[INFO] processing image 48/129\n",
      "dataset\\00000047.jpg\n",
      "[INFO] processing image 49/129\n",
      "dataset\\00000048.jpg\n",
      "[INFO] processing image 50/129\n",
      "dataset\\00000049.jpg\n",
      "[INFO] processing image 51/129\n",
      "dataset\\00000050.jpg\n",
      "[INFO] processing image 52/129\n",
      "dataset\\00000051.jpg\n",
      "[INFO] processing image 53/129\n",
      "dataset\\00000052.jpg\n",
      "[INFO] processing image 54/129\n",
      "dataset\\00000053.jpg\n",
      "[INFO] processing image 55/129\n",
      "dataset\\00000054.jpg\n",
      "[INFO] processing image 56/129\n",
      "dataset\\00000055.jpg\n",
      "[INFO] processing image 57/129\n",
      "dataset\\00000056.jpg\n",
      "[INFO] processing image 58/129\n",
      "dataset\\00000057.jpg\n",
      "[INFO] processing image 59/129\n",
      "dataset\\00000058.jpg\n",
      "[INFO] processing image 60/129\n",
      "dataset\\00000059.jpg\n",
      "[INFO] processing image 61/129\n",
      "dataset\\00000060.jpg\n",
      "[INFO] processing image 62/129\n",
      "dataset\\00000061.jpg\n",
      "[INFO] processing image 63/129\n",
      "dataset\\00000062.jpg\n",
      "[INFO] processing image 64/129\n",
      "dataset\\00000063.jpg\n",
      "[INFO] processing image 65/129\n",
      "dataset\\00000064.jpg\n",
      "[INFO] processing image 66/129\n",
      "dataset\\00000065.jpg\n",
      "[INFO] processing image 67/129\n",
      "dataset\\00000066.jpg\n",
      "[INFO] processing image 68/129\n",
      "dataset\\00000067.jpg\n",
      "[INFO] processing image 69/129\n",
      "dataset\\00000068.jpg\n",
      "[INFO] processing image 70/129\n",
      "dataset\\00000069.jpg\n",
      "[INFO] processing image 71/129\n",
      "dataset\\00000070.jpg\n",
      "[INFO] processing image 72/129\n",
      "dataset\\00000071.jpg\n",
      "[INFO] processing image 73/129\n",
      "dataset\\00000072.jpg\n",
      "[INFO] processing image 74/129\n",
      "dataset\\00000073.jpg\n",
      "[INFO] processing image 75/129\n",
      "dataset\\00000074.jpg\n",
      "[INFO] processing image 76/129\n",
      "dataset\\00000075.jpg\n",
      "[INFO] processing image 77/129\n",
      "dataset\\00000076.jpg\n",
      "[INFO] processing image 78/129\n",
      "dataset\\00000077.jpg\n",
      "[INFO] processing image 79/129\n",
      "dataset\\00000078.jpg\n",
      "[INFO] processing image 80/129\n",
      "dataset\\00000079.jpg\n",
      "[INFO] processing image 81/129\n",
      "dataset\\00000080.jpg\n",
      "[INFO] processing image 82/129\n",
      "dataset\\00000081.jpg\n",
      "[INFO] processing image 83/129\n",
      "dataset\\00000082.jpg\n",
      "[INFO] processing image 84/129\n",
      "dataset\\00000083.jpg\n",
      "[INFO] processing image 85/129\n",
      "dataset\\00000084.jpg\n",
      "[INFO] processing image 86/129\n",
      "dataset\\00000085.jpg\n",
      "[INFO] processing image 87/129\n",
      "dataset\\00000086.jpg\n",
      "[INFO] processing image 88/129\n",
      "dataset\\00000087.jpg\n",
      "[INFO] processing image 89/129\n",
      "dataset\\00000088.jpg\n",
      "[INFO] processing image 90/129\n",
      "dataset\\00000089.jpg\n",
      "[INFO] processing image 91/129\n",
      "dataset\\00000090.jpg\n",
      "[INFO] processing image 92/129\n",
      "dataset\\00000091.jpg\n",
      "[INFO] processing image 93/129\n",
      "dataset\\00000092.jpg\n",
      "[INFO] processing image 94/129\n",
      "dataset\\00000093.jpg\n",
      "[INFO] processing image 95/129\n",
      "dataset\\00000094.jpg\n",
      "[INFO] processing image 96/129\n",
      "dataset\\00000095.jpg\n",
      "[INFO] processing image 97/129\n",
      "dataset\\00000096.jpg\n",
      "[INFO] processing image 98/129\n",
      "dataset\\00000097.jpg\n",
      "[INFO] processing image 99/129\n",
      "dataset\\00000098.jpg\n",
      "[INFO] processing image 100/129\n",
      "dataset\\00000099.jpg\n",
      "[INFO] processing image 101/129\n",
      "dataset\\00000100.jpg\n",
      "[INFO] processing image 102/129\n",
      "dataset\\00000101.jpg\n",
      "[INFO] processing image 103/129\n",
      "dataset\\00000102.jpg\n",
      "[INFO] processing image 104/129\n",
      "dataset\\00000103.jpg\n",
      "[INFO] processing image 105/129\n",
      "dataset\\00000104.jpg\n",
      "[INFO] processing image 106/129\n",
      "dataset\\00000105.jpg\n",
      "[INFO] processing image 107/129\n",
      "dataset\\00000106.jpg\n",
      "[INFO] processing image 108/129\n",
      "dataset\\00000107.jpg\n",
      "[INFO] processing image 109/129\n",
      "dataset\\00000108.jpg\n",
      "[INFO] processing image 110/129\n",
      "dataset\\00000109.jpg\n",
      "[INFO] processing image 111/129\n",
      "dataset\\00000110.jpg\n",
      "[INFO] processing image 112/129\n",
      "dataset\\00000111.jpg\n",
      "[INFO] processing image 113/129\n",
      "dataset\\00000112.jpg\n",
      "[INFO] processing image 114/129\n",
      "dataset\\00000113.jpg\n",
      "[INFO] processing image 115/129\n",
      "dataset\\00000114.jpg\n",
      "[INFO] processing image 116/129\n",
      "dataset\\00000115.jpg\n",
      "[INFO] processing image 117/129\n",
      "dataset\\00000116.jpg\n",
      "[INFO] processing image 118/129\n",
      "dataset\\00000117.jpg\n",
      "[INFO] processing image 119/129\n",
      "dataset\\00000118.jpg\n",
      "[INFO] processing image 120/129\n",
      "dataset\\00000119.jpg\n",
      "[INFO] processing image 121/129\n",
      "dataset\\00000120.jpg\n",
      "[INFO] processing image 122/129\n",
      "dataset\\00000121.jpg\n",
      "[INFO] processing image 123/129\n",
      "dataset\\00000122.jpg\n",
      "[INFO] processing image 124/129\n",
      "dataset\\00000123.jpg\n",
      "[INFO] processing image 125/129\n",
      "dataset\\00000124.jpg\n",
      "[INFO] processing image 126/129\n",
      "dataset\\00000125.jpg\n",
      "[INFO] processing image 127/129\n",
      "dataset\\00000126.jpg\n",
      "[INFO] processing image 128/129\n",
      "dataset\\00000127.jpg\n",
      "[INFO] processing image 129/129\n",
      "dataset\\00000128.jpg\n"
     ]
    }
   ],
   "source": [
    "# loop over the image paths\n",
    "\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    # load the input image and convert it from RGB (OpenCV ordering)\n",
    "    # to dlib ordering (RGB)\n",
    "    print(\"[INFO] processing image {}/{}\".format(i + 1,\n",
    "        len(imagePaths)))\n",
    "    print(imagePath)\n",
    "    image = cv2.imread(imagePath)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # detect the (x, y)-coordinates of the bounding boxes\n",
    "    # corresponding to each face in the input image\n",
    "    boxes = face_recognition.face_locations(rgb,\n",
    "        model=args[\"detection_method\"])\n",
    "\n",
    "    # compute the facial embedding for the face\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\n",
    "    # build a dictionary of the image path, bounding box location,\n",
    "    # and facial encodings for the current image\n",
    "    d = [{\"imagePath\": imagePath, \"loc\": box, \"encoding\": enc}\n",
    "        for (box, enc) in zip(boxes, encodings)]\n",
    "    data.extend(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] serializing encodings...\n"
     ]
    }
   ],
   "source": [
    "# dump the facial encodings data to disk\n",
    "print(\"[INFO] serializing encodings...\")\n",
    "f = open(args[\"encodings\"], \"wb\")\n",
    "f.write(pickle.dumps(data))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
